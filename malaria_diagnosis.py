# -*- coding: utf-8 -*-
"""Malaria Diagnosis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qdijj-whAbOVa3PT4pCZLtbLajFpnylV

**Malaria Diagnosis**

* task - binary classification
* data
* modeling - CNN
* error sanctioning
* training and optimization
* performance measurement
* validating and testing
* corrective measures
"""

import tensorflow as tf #models
from tensorflow import keras

import numpy as np #math
import matplotlib.pyplot as plt #plot bar chart
import tensorflow_datasets as tfds
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Layer
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import BinaryAccuracy, FalseNegatives, FalsePositives, TruePositives, TrueNegatives, Precision, Recall, AUC
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau
import sklearn
from sklearn.metrics import confusion_matrix, roc_curve
import seaborn as sns

"""**DATA PREPATATION**"""

dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files= True, split=['train'])

dataset_info

print(dataset[0])

TRAIN_RATIO = 0.6
VAL_RATIO = 0.2
TEST_RATIO = 0.2

dataset2 = tf.data.Dataset.range(10)
DATASET_SIZE = len(dataset)

def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):
  DATASET_SIZE = len(dataset)

  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))

  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))
  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))

  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))
  return train_dataset, val_dataset, test_dataset

TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1

train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO )

#print(list(train_dataset.take(1).as_numpy_iterator()),
      #list(val_dataset.take(1).as_numpy_iterator()), list(test_dataset.take(1).as_numpy_iterator()))

train_dataset

"""**DATA VISUALIZATION**"""

for i, (image, label) in enumerate(train_dataset.take(16)):
  ax = plt.subplot(4, 4, i + 1)

  plt.imshow(image)
  plt.title(dataset_info.features['label'].int2str(label))
  plt.axis('off')

plt.figure(figsize=(10, 10))
for i, (image, label) in enumerate(train_dataset.take(16)):
    ax = plt.subplot(4, 4, i+1)
    plt.imshow(image[0])
    plt.title(dataset_info.features['label'].int2str(label[0].numpy()))
    plt.axis('off')
plt.show()

"""**DATA PREPROCESSING**"""

IM_SIZE = 224
def resize_rescale(image, label):
  #print("I was here")
  #tf.print("I was here")
  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label

def preprocess(image, label):
    image, label = resize_rescale(image, label)
    return tf.reshape(image, [-1, IM_SIZE, IM_SIZE, 3]), label

train_dataset = train_dataset.map(resize_rescale)

val_dataset = val_dataset.map(resize_rescale)
test_dataset = test_dataset.map(resize_rescale)

train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)

val_dataset = val_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)

train_dataset

val_dataset

"""⌨️ (7:08:50) How and Why ConvNets Work

## **MODEL CREATION and Training**

**Sequential API**
"""

model = tf.keras.Sequential([
    InputLayer(input_shape=(224, 224, 3)),
    Conv2D(filters=6, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu'),
    BatchNormalization(),
    MaxPool2D(pool_size=2, strides=2),

    Conv2D(filters=16, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu'),
    BatchNormalization(),
    MaxPool2D(pool_size=2, strides=2),

    Flatten(),
    Dense(100, activation = "relu"),
    BatchNormalization(),
    Dense(10, activation = "relu"),
    BatchNormalization(),
    Dense(1, activation = "sigmoid"),
])

model.summary()

"""**Binary Crossentropy Loss**

"""

y_true = [0,1,0,0]
y_pred = [0.6,0.51,0.94,1]
bce = tf.keras.losses.BinaryCrossentropy()
bce(y_true, y_pred)

model.compile(optimizer =Adam(learning_rate = 0.01),
              loss = BinaryCrossentropy(),
              metrics = 'accuracy')

print(train_dataset)
print(val_dataset)



history = model.fit(train_dataset, validation_data = val_dataset,  epochs=20, verbose=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.show()

"""**Model Evaluation and Testing**"""

test_dataset = test_dataset.batch(1)
test_dataset

def parasite_or_not(x):
  if(x<0.5):
    return str('P')
  else:
    return str('U')

model.predict(test_dataset.take(1))[0][0]

for i, (image, label) in enumerate(test_dataset.take(9)):
  ax = plt.subplot(3, 3, i+1)
  plt. imshow(image[0])
  plt.title(str(parasite_or_not(label.numpy()[0])) + ":" + str(parasite_or_not(model.predict(image)[0][0])))

"""**Saving to and Loading from Google Drive**

I need to look at this more detailed later

**Functional API**
"""

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Lenet Model ")
#extraction features
x = Conv2D(filters=6, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(func_input)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=2, strides=2)(x)

x = Conv2D(filters=16, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(x)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=2, strides=2)(x)
#classifying
x = Flatten()(x)
x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)
x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)
func_output = Dense(1, activation = "sigmoid")(x)

lenet_model = Model(func_input, func_output, name = "Lenet_Model")
lenet_model.summary()

lenet_model.compile(optimizer =Adam(learning_rate = 0.01),
              loss = BinaryCrossentropy(),
              metrics = 'accuracy')

history = lenet_model.fit(train_dataset, validation_data = val_dataset,  epochs=20, verbose=1)

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
#extraction features
x = Conv2D(filters=6, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(func_input)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=2, strides=2)(x)

x = Conv2D(filters=16, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(x)
x = BatchNormalization()(x)
output = MaxPool2D(pool_size=2, strides=2)(x)

feature_extractor_model = Model(func_input, output, name = "Feature_Extractor")
feature_extractor_model.summary()

#classifying
func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
x = feature_extractor_model(func_input)
x = Flatten()(x)
x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)
x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)
func_output = Dense(1, activation = "sigmoid")(x)

lenet_model = Model(func_input, func_output, name = "Lenet_Model")
lenet_model.summary()

"""**Model Subclassing**"""

class FeatureExtractor(Layer):
  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):
    super(FeatureExtractor,self).__init__()

    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides=strides , padding=padding ,activation=activation )
    self.batch_1 = BatchNormalization()
    self.pool_1 = MaxPool2D(pool_size, strides = 2*strides)

    self.conv_2 = Conv2D(filters = filters*2, kernel_size = kernel_size, strides=strides , padding=padding ,activation=activation )
    self.batch_2 = BatchNormalization()
    self.pool_2 = MaxPool2D(pool_size, strides=2*strides)

def call(self, x, training):
  x = self.conv_1(x)
  x = self.batch_1(x)
  x = self.pool_1(x)

  x = self.conv_2(x)
  x = self.batch_2(x)
  x = self.pool_2(x)

  return x


feature_sub_classed = FeatureExtractor(8, 3, 1, "valid", "relu", 2)

#classifying
func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
x = feature_sub_classed(func_input)
x = Flatten()(x)
x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)
x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)
func_output = Dense(1, activation = "sigmoid")(x)

lenet_model = Model(func_input, func_output, name = "Lenet_Model")
lenet_model.summary()

feature_extractor_seq_model = tf.keras.Sequential([
                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),

                             Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),

                             Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),



])
feature_extractor_seq_model.summary()

"""**Callable Model**"""

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")

x = feature_extractor_seq_model(func_input)

x = Flatten()(x)

x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)

x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)

func_output = Dense(1, activation = "sigmoid")(x)

lenet_model_func = Model(func_input, func_output, name = "Lenet_Model")
lenet_model_func.summary()

class LenetModel(Model):
  def __init__(self):
    super(LenetModel, self).__init__()
    self.feature_extractor  = FeatureExtractor(8,3,1,"valid","relu", 2)

    self.flatten = Flatten()
    self.dense_1 = Dense(100, activation = "relu")
    self.batch_1 = BatchNormalization()

    self.dense_2 = Dense(10, activation = "relu")
    self.batch_2 = BatchNormalization()

    self.dense_3 = Dense(1, activation = "sigmoid")

  def call(self, x, training):

    x = self.feature_extractor(x)
    x = self.flatten(x)
    x = self.dense_1(x)
    x = self.batch_1(x)
    x = self.dense_2(x)
    x = self.batch_2(x)
    x = self.dense_3(x)
    return x

lenet_sub_classed = LenetModel()
lenet_sub_classed(tf.zeros([1,224,224,3]))
lenet_sub_classed.summary()

lenet_sub_classed.compile(optimizer =Adam(learning_rate = 0.01),
              loss = BinaryCrossentropy(),
              metrics = 'accuracy')

history = lenet_sub_classed.fit(train_dataset, validation_data = val_dataset,  epochs=20, verbose=1)

"""**Custom Layers**"""

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
#extraction features
x = Conv2D(filters=6, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(func_input)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=2, strides=2)(x)

x = Conv2D(filters=16, kernel_size=3, strides = 1, padding = 'valid',activation = 'relu')(x)
x = BatchNormalization()(x)
output = MaxPool2D(pool_size=2, strides=2)(x)

feature_extractor_model = Model(func_input, output, name = "Feature_Extractor")
feature_extractor_model.summary()

#classifying
func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
x = feature_extractor_model(func_input)
x = Flatten()(x)
x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)
x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)
func_output = Dense(1, activation = "sigmoid")(x)

lenet_model = Model(func_input, func_output, name = "Lenet_Model")
lenet_model.summary()

class FeatureExtractor(Layer):
  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):
    super(FeatureExtractor,self).__init__()

    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides=strides , padding=padding ,activation=activation )
    self.batch_1 = BatchNormalization()
    self.pool_1 = MaxPool2D(pool_size, strides = 2*strides)

    self.conv_2 = Conv2D(filters = filters*2, kernel_size = kernel_size, strides=strides , padding=padding ,activation=activation )
    self.batch_2 = BatchNormalization()
    self.pool_2 = MaxPool2D(pool_size, strides=2*strides)

def call(self, x, training):
  x = self.conv_1(x)
  x = self.batch_1(x)
  x = self.pool_1(x)

  x = self.conv_2(x)
  x = self.batch_2(x)
  x = self.pool_2(x)

  return x


feature_sub_classed = FeatureExtractor(8, 3, 1, "valid", "relu", 2)

#classifying
func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")
x = feature_sub_classed(func_input)
x = Flatten()(x)
x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)
x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)
func_output = Dense(1, activation = "sigmoid")(x)

lenet_model = Model(func_input, func_output, name = "Lenet_Model")
lenet_model.summary()

feature_extractor_seq_model = tf.keras.Sequential([
                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),

                             Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),

                             Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),



])
feature_extractor_seq_model.summary()

func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = "Input Image")

x = feature_extractor_seq_model(func_input)

x = Flatten()(x)

x = Dense(100, activation = "relu")(x)
x = BatchNormalization()(x)

x = Dense(10, activation = "relu")(x)
x = BatchNormalization()(x)

func_output = Dense(1, activation = "sigmoid")(x)

lenet_model_func = Model(func_input, func_output, name = "Lenet_Model")
lenet_model_func.summary()

class LenetModel(Model):
  def __init__(self):
    super(LenetModel, self).__init__()
    self.feature_extractor  = FeatureExtractor(8,3,1,"valid","relu", 2)

    self.flatten = Flatten()
    self.dense_1 = Dense(100, activation = "relu")
    self.batch_1 = BatchNormalization()

    self.dense_2 = Dense(10, activation = "relu")
    self.batch_2 = BatchNormalization()

    self.dense_3 = Dense(1, activation = "sigmoid")

  def call(self, x, training):

    x = self.feature_extractor(x)
    x = self.flatten(x)
    x = self.dense_1(x)
    x = self.batch_1(x)
    x = self.dense_2(x)
    x = self.batch_2(x)
    x = self.dense_3(x)
    return x

lenet_sub_classed = LenetModel()
lenet_sub_classed(tf.zeros([1,224,224,3]))
lenet_sub_classed.summary()

lenet_sub_classed.compile(optimizer =Adam(learning_rate = 0.01),
              loss = BinaryCrossentropy(),
              metrics = 'accuracy')

class NeuralearnDense(Layer):
  def __init__(self, output_units, activation):
    super(NeuralearnDense, self).__init__()
    self.output_units = output_units
    self.activation = activation

  def build(self, input_features_shape):
    self.w = self.add_weight(shape = (input_features_shape[-1], self.output_units), initializer = "random_normal", trainable = True)
    self.b = self.add_weight(shape = (self.output_units,), initializer = "random_normal", trainable = True)

  def call(self, input_features):

    pre_output = tf.matmul(input_features, self.w) + self.b

    if(self.activation == "relu"):
      return tf.nn.relu(pre_output)

    elif(self.activation == "sigmoid"):
      return tf.math.sigmoid(pre_output)

    else:
      return pre_output

IM_SIZE = 224
lenet_custom_model = tf.keras.Sequential([
                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),

                             Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),

                             Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),
                             BatchNormalization(),
                             MaxPool2D (pool_size = 2, strides= 2),

                             Flatten(),

                             NeuralearnDense(100, activation = "relu"),
                             BatchNormalization(),

                             NeuralearnDense(10, activation = "relu"),
                             BatchNormalization(),

                             NeuralearnDense(1, activation = "sigmoid"),

])
lenet_custom_model.summary()

"""## Evaluating Classification Models

### Precision, Recall and Accuracy

* PRECISION TP/TP+FP
* RECALL TP/TP+FN
* ACCURACY TN+TP/TN+TP+FN+FP
* F1-SCORE 2PR/P+R
* SPECIFICITY TN/TN+FP
"""

metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'),
                BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]

lenet_custom_model.compile(optimizer =Adam(learning_rate = 0.01),
              loss = BinaryCrossentropy(),
              metrics = metrics)

history = lenet_custom_model.fit(train_dataset, validation_data = val_dataset,  epochs=5, verbose=1)

"""**Model Evaluation and Testing**"""

test_dataset

lenet_custom_model.evaluate(test_dataset)

"""### Visualizing Confusion Matrix"""

labels = []
inp = []
for x,y in test_dataset.as_numpy_iterator():
  labels.append(y)
  inp.append(x)

labels = np.array([i[0] for i in labels])

predicted = lenet_model.predict(np.array(inp)[:,0,...])
print(predicted[:,0])

threshold = 0.5

cm = confusion_matrix(labels, predicted> threshold)
print(cm)
plt.figure(figsize=(8,8))

sns.heatmap(cm, annot=True,)
plt.title('Confusion matrix - {}'.format(threshold))
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.axis('off')

"""### ROC Plots"""

fp, tp, threshold = roc_curve(labels, predicted)
plt.plot(fp, tp)
plt.xlabel("False Positive rate")
plt.ylabel("True Positive rate")

plt.grid()

skip = 20

for i in range(0, len(thresholds), skip):
  plt.text(fp[i], tp[i], thresholds[i])

plt.show()

"""## Improving Model Performance

### TensorFlow Callbacks
"""

class LossCallback(Callback):
  def on_epoch_end(self, epoch, logs):
    print("\n for each number {} the model has a loss of {}".format(epoch+1, logs["loss"]))
  def on_batch_end(self, bacth, logs):
    print("\n for batch number {} the model has a loss of {}".format(batch+1, logs))

"""CSVLogger - we can save our acc, auc etc."""

csv_callback = CSVLogger(
    'logs.csv', separator=',', append = False
)

"""EarlyStopping - solution for overfitting"""

es_callback = EarlyStopping(
    monitor='val_loss', min_delta=0, patience = 0, verbose=0,
    mode='auto', baseline=None, restore_best_weights=False
)

"""LearningRateScheduler - optimize learning rate"""

def schedular(epoch, lr):
  if epoch < 10:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

scheduler_callback = LearningRateScheduler(schedular, verbose = 1)

"""mxnet , learning_rate_schedules website

Loading and saving
"""

lenet_model.save("lenet")
lenet_model.save_weights("weights/lenet_weights")
lenet_weights_model = lenet_model.load_weights("weights/lenet_weights")

"""ModelCheckpoint - save weights at some frequency"""

checkpoint_callback = ModelCheckpoint(
    "checkpoints/",
    monitor='val_loss',
    verbose = 0,
    save_best_only= False,
    save_weights_only = False,
    mode = 'auto',
    save_freq='epoch',

)

"""ReduceLearningRateOnPlateau"""

plateau_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5, min_lr=0.001)

"""**Module: tf.image**

Functions
adjust_brightness(...): Adjust the brightness of RGB or Grayscale images.

adjust_contrast(...): Adjust contrast of RGB or grayscale images.

adjust_gamma(...): Performs Gamma Correction.

adjust_hue(...): Adjust hue of RGB images.

adjust_jpeg_quality(...): Adjust jpeg encoding quality of an image.

adjust_saturation(...): Adjust saturation of RGB images.

central_crop(...): Crop the central region of the image(s).

combined_non_max_suppression(...): Greedily selects a subset of bounding boxes in descending order of score.

convert_image_dtype(...): Convert image to dtype, scaling its values if needed.

crop_and_resize(...): Extracts crops from the input image tensor and resizes them.

crop_to_bounding_box(...): Crops an image to a specified bounding box.

decode_and_crop_jpeg(...): Decode and Crop a JPEG-encoded image to a uint8 tensor.

decode_bmp(...): Decode the first frame of a BMP-encoded image to a uint8 tensor.

decode_gif(...): Decode the frame(s) of a GIF-encoded image to a uint8 tensor.

decode_image(...): Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.

decode_jpeg(...): Decode a JPEG-encoded image to a uint8 tensor.

decode_png(...): Decode a PNG-encoded image to a uint8 or uint16 tensor.

draw_bounding_boxes(...): Draw bounding boxes on a batch of images.

encode_jpeg(...): JPEG-encode an image.

encode_png(...): PNG-encode an image.

extract_glimpse(...): Extracts a glimpse from the input tensor.

extract_jpeg_shape(...): Extract the shape information of a JPEG-encoded image.

extract_patches(...): Extract patches from images.

flip_left_right(...): Flip an image horizontally (left to right).

flip_up_down(...): Flip an image vertically (upside down).

generate_bounding_box_proposals(...): Generate bounding box proposals from encoded bounding boxes.

grayscale_to_rgb(...): Converts one or more images from Grayscale to RGB.

hsv_to_rgb(...): Convert one or more images from HSV to RGB.

image_gradients(...): Returns image gradients (dy, dx) for each color channel.

is_jpeg(...): Convenience function to check if the 'contents' encodes a JPEG image.

non_max_suppression(...): Greedily selects a subset of bounding boxes in descending order of score.

non_max_suppression_overlaps(...): Greedily selects a subset of bounding boxes in descending order of score.

non_max_suppression_padded(...): Greedily selects a subset of bounding boxes in descending order of score.

non_max_suppression_with_scores(...): Greedily selects a subset of bounding boxes in descending order of score.

pad_to_bounding_box(...): Pad image with zeros to the specified height and width.

per_image_standardization(...): Linearly scales each image in image to have mean 0 and variance 1.

psnr(...): Returns the Peak Signal-to-Noise Ratio between a and b.

random_brightness(...): Adjust the brightness of images by a random factor.

random_contrast(...): Adjust the contrast of an image or images by a random factor.

random_crop(...): Randomly crops a tensor to a given size.

random_flip_left_right(...): Randomly flip an image horizontally (left to right).

random_flip_up_down(...): Randomly flips an image vertically (upside down).

random_hue(...): Adjust the hue of RGB images by a random factor.

random_jpeg_quality(...): Randomly changes jpeg encoding quality for inducing jpeg noise.

random_saturation(...): Adjust the saturation of RGB images by a random factor.

resize(...): Resize images to size using the specified method.

resize_with_crop_or_pad(...): Crops and/or pads an image to a target width and height.

resize_with_pad(...): Resizes and pads an image to a target width and height.

rgb_to_grayscale(...): Converts one or more images from RGB to Grayscale.

rgb_to_hsv(...): Converts one or more images from RGB to HSV.

rgb_to_yiq(...): Converts one or more images from RGB to YIQ.

rgb_to_yuv(...): Converts one or more images from RGB to YUV.

rot90(...): Rotate image(s) by 90 degrees.

sample_distorted_bounding_box(...): Generate a single randomly distorted bounding box for an image.

sobel_edges(...): Returns a tensor holding Sobel edge maps.

ssim(...): Computes SSIM index between img1 and img2.

ssim_multiscale(...): Computes the MS-SSIM between img1 and img2.

stateless_random_brightness(...): Adjust the brightness of images by a random factor deterministically.

stateless_random_contrast(...): Adjust the contrast of images by a random factor deterministically.

stateless_random_crop(...): Randomly crops a tensor to a given size in a deterministic manner.

stateless_random_flip_left_right(...): Randomly flip an image horizontally (left to right) deterministically.

stateless_random_flip_up_down(...): Randomly flip an image vertically (upside down) deterministically.

stateless_random_hue(...): Adjust the hue of RGB images by a random factor deterministically.

stateless_random_jpeg_quality(...): Deterministically radomize jpeg encoding quality for inducing jpeg noise.

stateless_random_saturation(...): Adjust the saturation of RGB images by a random factor deterministically.

stateless_sample_distorted_bounding_box(...): Generate a randomly distorted bounding box for an image deterministically.

total_variation(...): Calculate and return the total variation for one or more images.

transpose(...): Transpose image(s) by swapping the height and width dimension.

yiq_to_rgb(...): Converts one or more images from YIQ to RGB.

yuv_to_rgb(...): Converts one or more images from YUV to RGB.

## Data Preprocessing

Data Augmentation
"""

def visualize(original, augmented):
  plt.subplot(1,2,1)
  plt.imshow(original)

  plt.subplot(1,2,2)
  plt.imshow(augmented)

original_image, label = next(iter(train_dataset))

augmented_image = tf.image.adjust_saturation(original_image, saturation_factor = 0.3)#central_crop(original_image, 0.8)

visualize(original_image, augmented_image)

IM_SIZE = 224

def resize_rescale(image, label):

  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label

def augment(image, label):
  image, label = resize_rescale(image, label)

  image = tf.image.rot90(image)
  image = tf.image.adjust_saturation(image, saturation_factor = 0.3)
  image = tf.image.flip_left_right(image)

  return image, label

train_dataset = train_dataset.map(augment)
val_dataset = val_dataset.map(resize_rescale)
test_dataset = test_dataset.map(resize_rescale)
train_dataset

BATCH_SIZE = 32
train_dataset = (
    train_dataset
    .shuffle(buffer_size = 8, reshuffle_each_iteration = True)
    .map(augment)
    .batch(BATCH_SIZE)
    .prefetch(tf.data.AUTOTUNE)
)

val_dataset = (
    val_dataset
    .shuffle(buffer_size = 8, reshuffle_each_iteration = True)
    .map(resize_rescale)
    .batch(BATCH_SIZE)
    .prefetch(tf.data.AUTOTUNE)
)

"""## Advanced TensorFlow Topics

Custom Loss Class
"""

FACTOR = 1
class CustomBCE(tf.keras.losses.Loss):
  def __init__(self, FACTOR):
    super(CustomBCE, self).__init__()
    self.FACTOR = FACTOR

  def call(self,y_true, y_pred):
    bce = BinaryCrossentropy()
    return bce(y_true, y_pred)*self.FACTOR

"""### Custom Loss and Metrics

Custom loss with parameters
"""

FACTOR = 1
def custom_bce(FACTOR):
  def loss(y_true, y_pred):
    bce = BinaryCrossentropy()
    return bce(y_true, y_pred)*FACTOR

  return loss

model.compile(optimizer = Adam(learning_rate = 0.01),
              loss = CustomBCE(FACTOR),
              metrics = metrics, )